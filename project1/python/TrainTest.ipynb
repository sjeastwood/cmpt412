{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from load_mnist import load_mnist\n",
    "from init_convnet import init_convnet\n",
    "from conv_net import conv_net\n",
    "from utils import sgd_momentum, get_lr, get_lenet\n",
    "import copy\n",
    "from scipy.io import savemat\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(100000)\n",
    "\n",
    "# Network definition\n",
    "layers = get_lenet()\n",
    "\n",
    "# Loading data\n",
    "fullset = False\n",
    "xtrain, ytrain, xvalidate, yvalidate, xtest, ytest = load_mnist(fullset)\n",
    "xtrain = np.hstack((xtrain, xvalidate))\n",
    "ytrain = np.hstack((ytrain, yvalidate))\n",
    "m_train = xtrain.shape[1]\n",
    "batch_size = 100\n",
    "\n",
    "# Parameters initialization\n",
    "mu = 0.9\n",
    "epsilon = 0.01\n",
    "gamma = 0.0001\n",
    "power = 0.75\n",
    "weight_decay = 0.0005\n",
    "w_lr = 1\n",
    "b_lr = 2\n",
    "\n",
    "test_interval = 500\n",
    "display_interval = 50\n",
    "snapshot = 500\n",
    "max_iter = 2000\n",
    "\n",
    "# Use the following to train from scratch\n",
    "params = init_convnet(layers)\n",
    "\n",
    "params_winc = copy.deepcopy(params)\n",
    "\n",
    "# Training the network\n",
    "new_order = np.random.permutation(m_train)\n",
    "xtrain = xtrain[:, new_order]\n",
    "ytrain = ytrain[:, new_order]\n",
    "curr_batch = 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if curr_batch >= m_train:\n",
    "    new_order = np.random.permutation(m_train)\n",
    "    xtrain = xtrain[:, new_order]\n",
    "    ytrain = ytrain[:, new_order]\n",
    "    curr_batch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = xtrain[:, curr_batch:curr_batch+batch_size]\n",
    "y_batch = ytrain[:, curr_batch:curr_batch+batch_size]\n",
    "curr_batch += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from conv_layer import conv_layer_forward, conv_layer_backward\n",
    "from pooling_layer import pooling_layer_forward, pooling_layer_backward\n",
    "from inner_product import inner_product_forward, inner_product_backward\n",
    "from relu import relu_forward, relu_backward\n",
    "from mlrloss import mlrloss\n",
    "from conv_net import convnet_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cp, param_grad = conv_net(params, layers, x_batch, y_batch)\n",
    "data = x_batch\n",
    "labels = y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "output = convnet_forward(params, layers, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "\n",
    "# Layer 1: DATA\n",
    "layers.append({\n",
    "    'type': 'DATA',\n",
    "    'height': 28,\n",
    "    'width': 28,\n",
    "    'channel': 1,\n",
    "    'batch_size': batch_size\n",
    "})\n",
    "\n",
    "# Layer 2: CONV\n",
    "layers.append({\n",
    "    'type': 'CONV',\n",
    "    'num': 20,\n",
    "    'k': 5,\n",
    "    'stride': 1,\n",
    "    'pad': 0,\n",
    "    'group': 1\n",
    "})\n",
    "\n",
    "# Layer 3: RELU\n",
    "layers.append({\n",
    "    'type': 'RELU'\n",
    "})\n",
    "\n",
    "# Layer 4: POOLING\n",
    "layers.append({\n",
    "    'type': 'POOLING',\n",
    "    'k': 2,\n",
    "    'stride': 2,\n",
    "    'pad': 0\n",
    "})\n",
    "\n",
    "# Layer 5: CONV\n",
    "layers.append({\n",
    "    'type': 'CONV',\n",
    "    'k': 5,\n",
    "    'stride': 1,\n",
    "    'pad': 0,\n",
    "    'group': 1,\n",
    "    'num': 50\n",
    "})\n",
    "\n",
    "# Layer 6: RELU\n",
    "layers.append({\n",
    "    'type': 'RELU'\n",
    "})\n",
    "\n",
    "# Layer 7: POOLING\n",
    "layers.append({\n",
    "    'type': 'POOLING',\n",
    "    'k': 2,\n",
    "    'stride': 2,\n",
    "    'pad': 0\n",
    "})\n",
    "\n",
    "# Layer 8: IP\n",
    "layers.append({\n",
    "    'type': 'IP',\n",
    "    'num': 500,\n",
    "    'init_type': 'uniform'\n",
    "})\n",
    "\n",
    "# Layer 9: RELU\n",
    "layers.append({\n",
    "    'type': 'RELU'\n",
    "})\n",
    "\n",
    "# Layer 10: LOSS\n",
    "layers.append({\n",
    "    'type': 'LOSS',\n",
    "    'num': 10\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(layers)\n",
    "batch_size = layers[0]['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(layers)\n",
    "assert layers[0]['type'] == 'DATA', 'first layer must be data layer'\n",
    "\n",
    "output = [{}]\n",
    "output[0]['data'] = data\n",
    "output[0]['height'] = layers[0]['height']\n",
    "output[0]['width'] = layers[0]['width']\n",
    "output[0]['channel'] = layers[0]['channel']\n",
    "output[0]['batch_size'] = layers[0]['batch_size']\n",
    "output[0]['diff'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, l-1):\n",
    "        layer_type = layers[i]['type']\n",
    "        if layer_type == 'CONV':\n",
    "            output.append(conv_layer_forward(output[i-1], layers[i], params[i-1]))\n",
    "        elif layer_type == 'POOLING':\n",
    "            output.append(pooling_layer_forward(output[i-1], layers[i]))\n",
    "        elif layer_type == 'IP':\n",
    "            output.append(inner_product_forward(output[i-1], layers[i], params[i-1]))\n",
    "        elif layer_type == 'RELU':\n",
    "            output.append(relu_forward(output[i-1]))\n",
    "        else:\n",
    "            raise Exception('Invalid layer type: %s' % layer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss layer\n",
    "i = l - 1\n",
    "assert layers[i]['type'] == 'LOSS', 'last layer must be loss layer'\n",
    "wb = np.concatenate([params[i-1]['w'].ravel(), params[i-1]['b'].ravel()])\n",
    "cost, grad, input_od, percent = mlrloss(wb, output[i-1]['data'], labels, layers[i]['num'], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grad = []\n",
    "if test is False:\n",
    "    pg = {}\n",
    "    pg['w'] = np.reshape(grad[:params[i-1]['w'].size], params[i-1]['w'].shape) / batch_size\n",
    "    pg['b'] = np.reshape(grad[-params[i-1]['b'].size:], params[i-1]['b'].shape) / batch_size\n",
    "    param_grad.append(pg)\n",
    "\n",
    "    for i in range(l-2, 0, -1):\n",
    "        layer_type = layers[i]['type']\n",
    "        output[i]['diff'] = input_od\n",
    "\n",
    "        pg = {}\n",
    "\n",
    "        if layer_type == 'CONV':\n",
    "            pg, input_od = conv_layer_backward(output[i], output[i-1], layers[i], params[i-1])\n",
    "        elif layer_type == 'POOLING':\n",
    "            input_od = pooling_layer_backward(output[i], output[i-1], layers[i])\n",
    "            pg['w'] = []\n",
    "            pg['b'] = []\n",
    "        elif layer_type == 'IP':\n",
    "            pg, input_od = inner_product_backward(output[i], output[i-1], layers[i], params[i-1])\n",
    "        elif layer_type in 'RELU':\n",
    "            input_od = relu_backward(output[i], output[i-1], layers[i])\n",
    "            pg['w'] = []\n",
    "            pg['b'] = []\n",
    "\n",
    "        pg['w'] = np.array(pg['w']) / batch_size\n",
    "        pg['b'] = np.array(pg['b']) / batch_size\n",
    "        param_grad.append(pg)\n",
    "        print(pg)\n",
    "\n",
    "# reverse the param_grad list\n",
    "param_grad = param_grad[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = {'cost': cost / batch_size, 'percent': percent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(param_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
