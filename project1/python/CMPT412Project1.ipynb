{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from utils import im2col_conv, col2im_conv, im2col_conv_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOBALS\n",
    "resultsdir = '../results'\n",
    "os.makedirs(resultsdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_2(input_data, output, params, testname):\n",
    "    global resultsdir\n",
    "    \n",
    "    fig, ax = plt.subplots(input_data['batch_size'], 1)\n",
    "    for batch in range(input_data['batch_size']):\n",
    "        # outputs\n",
    "        img = output['data'][:,batch].reshape(output['height'], output['width'])\n",
    "        \n",
    "        # middle\n",
    "        img = np.hstack([params['w'].T, np.ones(img.shape), params['b'].reshape(-1, 1), np.zeros(img.shape), img])\n",
    "        \n",
    "        # inputs\n",
    "        imgin = input_data['data'][:,batch].reshape(input_data['height'], input_data['width']).T\n",
    "        imgin_padded = np.hstack([imgin, np.zeros((imgin.shape[0], 4))])\n",
    "        img = np.vstack([imgin_padded, np.zeros(imgin_padded.shape), np.zeros(imgin_padded.shape), np.ones(imgin_padded.shape), img])\n",
    "        \n",
    "        ax[batch].imshow(img)\n",
    "        ax[batch].set_title(f'Batch {batch + 1}')\n",
    "        ax[batch].set_axis_off()\n",
    "        \n",
    "    fig.suptitle(testname)\n",
    "    \n",
    "    filename = f\"{resultsdir}/{testname}.png\"\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product_forward(input, layer, param):\n",
    "    \"\"\"\n",
    "    Forward pass of inner product layer.\n",
    "\n",
    "    Parameters:\n",
    "    - input (dict): Contains the input data.\n",
    "    - layer (dict): Contains the configuration for the inner product layer.\n",
    "    - param (dict): Contains the weights and biases for the inner product layer.\n",
    "    \"\"\"\n",
    "\n",
    "    d, k = input[\"data\"].shape\n",
    "    n = param[\"w\"].shape[1]\n",
    "\n",
    "    ###### Fill in the code here ######\n",
    "    W = param[\"w\"]\n",
    "    X = input[\"data\"]\n",
    "    b = param[\"b\"]\n",
    "    \n",
    "    f = np.dot(W.T,X) + b.T\n",
    "    \n",
    "    # Initialize output data structure\n",
    "    output = {\n",
    "        \"height\": n,\n",
    "        \"width\": 1,\n",
    "        \"channel\": 1,\n",
    "        \"batch_size\": k,\n",
    "        \"data\": f #np.zeros((n, k)) # replace 'data' value with your implementation\n",
    "    }\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inner_1():\n",
    "    # Initialize the 'input' structure\n",
    "    input_data = {}\n",
    "    input_data['data'] = np.zeros((25,2))\n",
    "    input_data['data'] = input_data['data'].T\n",
    "    input_data['data'].flat[5::3] = 1.0\n",
    "    input_data['data'].flat[6::3] = 0.5\n",
    "    input_data['data'] = input_data['data'].T\n",
    "    input_data['height'] = 25\n",
    "    input_data['width'] = 1\n",
    "    input_data['channel'] = 1\n",
    "    input_data['batch_size'] = 2\n",
    "\n",
    "    # Initialize the 'layer' structure\n",
    "    layer = {}\n",
    "    layer['type'] = 'IP'\n",
    "    layer['num'] = 25\n",
    "\n",
    "    # Initialize the 'params' structure\n",
    "    params = {}\n",
    "    params['w'] = np.eye(25)\n",
    "    params['w'].flat[:25*10] = 0\n",
    "    params['w'][1, 4] = 0.5\n",
    "    params['w'][2, 3] = 0.5\n",
    "    params['b'] = np.zeros((1,25))\n",
    "    params['b'][0,1] = 0.5\n",
    "    params['b'][0,3] = 0.5\n",
    "\n",
    "    output = inner_product_forward(input_data, layer, params)\n",
    "\n",
    "    display_results_2(input_data, output, params, 'Inner Product Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pooling_1():\n",
    "    input_data = {'data': np.zeros((36*3,2))}\n",
    "    input_data['data'][12, 0] = 0.5\n",
    "    input_data['data'][13, 0] = 0.25\n",
    "    input_data['data'][14, 0] = 0.5\n",
    "    input_data['data'][19+72, 0] = 0.75\n",
    "\n",
    "    input_data['data'][14, 1] = 0.25\n",
    "    input_data['data'][15, 1] = 0.75\n",
    "    input_data['data'][5+36, 1] = 0.75\n",
    "    input_data['data'][11+72, 1] = 0.75\n",
    "    input_data['width'] = 6\n",
    "    input_data['height'] = 6\n",
    "    input_data['channel'] = 3\n",
    "    input_data['batch_size'] = 2\n",
    "\n",
    "    layer = {'type': 'POOLING', 'k': 2, 'stride': 2, 'pad': 0}\n",
    "\n",
    "    output = pooling_layer_forward(input_data, layer)\n",
    "    display_results(input_data, output, 'Pooling Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(input_data, output, testname):\n",
    "    global resultsdir\n",
    "    \n",
    "    fig, ax = plt.subplots(input_data['batch_size'], 2)\n",
    "    for batch in range(input_data['batch_size']):\n",
    "        # outputs\n",
    "        img1 = output['data'][:,batch].reshape(output['channel'], output['height'], output['width'])\n",
    "        img1 = np.transpose(img1, (1, 2, 0))\n",
    "        ax[batch, 1].imshow(img1)\n",
    "        ax[batch, 1].set_title(f'Output {batch + 1}')\n",
    "        ax[batch, 1].set_axis_off()\n",
    "\n",
    "        # inputs\n",
    "        imgin1 = input_data['data'][:,batch].reshape(input_data['channel'], input_data['height'], input_data['width'])\n",
    "        imgin1 = np.transpose(imgin1, (1, 2, 0))\n",
    "        ax[batch, 0].imshow(imgin1)\n",
    "        ax[batch, 0].set_title(f'Input {batch + 1}')\n",
    "        ax[batch, 0].set_axis_off()\n",
    "\n",
    "    fig.suptitle(testname)\n",
    "    \n",
    "    filename = f\"{resultsdir}/{testname}.png\"\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_layer_forward(input, layer):\n",
    "    \"\"\"\n",
    "    Forward pass for the pooling layer.\n",
    "\n",
    "    Parameters:\n",
    "    - input (dict): Contains the input data.\n",
    "    - layer (dict): Layer configuration containing parameters such as kernel size, padding, stride, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    h_in = input['height']\n",
    "    w_in = input['width']\n",
    "    c = input['channel']\n",
    "    batch_size = input['batch_size']\n",
    "    k = layer['k']\n",
    "    pad = layer['pad']\n",
    "    stride = layer['stride']\n",
    "\n",
    "    h_out = int((h_in + 2 * pad - k) / stride + 1)\n",
    "    w_out = int((w_in + 2 * pad - k) / stride + 1)\n",
    "    \n",
    "    ###### Fill in the code here ######\n",
    "    output_data = np.zeros((c*h_out*w_out,batch_size))\n",
    "\n",
    "    for batch in range(batch_size):\n",
    "        #input image reshaped\n",
    "        img = input['data'][:,batch].reshape(c, h_in, w_in) #need to account for padding\n",
    "\n",
    "        # add padding if it exists\n",
    "        pad_img = np.zeros((c,pad*2+h_in,pad*2+w_in))\n",
    "        for chan in range(c):\n",
    "            pad_img[chan] = np.pad(img[chan],pad)\n",
    "\n",
    "        #matrix to hold the pooled layers\n",
    "        pool_mtx = np.zeros((c,h_out,w_out))\n",
    "\n",
    "        #slide kernel across pad_img and grab max\n",
    "\n",
    "        row = 0\n",
    "        col = 0 #to control the pool_mtx row and col to be filled in\n",
    "        #go across rows with j\n",
    "        for j in range(0,pad_img.shape[1],stride): #stride is 2\n",
    "\n",
    "            col = 0 #reset column for next row\n",
    "\n",
    "            #go across columns with i\n",
    "            for i in range(0,pad_img.shape[2],stride):\n",
    "\n",
    "                #go across channels\n",
    "                for chan in range(c):\n",
    "                    #grab max from the kernel slice of image mtx\n",
    "                    pool_mtx[chan,row,col] = np.max(pad_img[chan,j:j+stride,i:i+stride])\n",
    "\n",
    "                col = col + 1 # move on to the next coumn\n",
    "\n",
    "            row = row + 1 # increment row when columns are done\n",
    "\n",
    "        output_data[:,batch] = pool_mtx.reshape(1,c*h_out*w_out)[0]\n",
    "    \n",
    "    output = {}\n",
    "    output['height'] = h_out\n",
    "    output['width'] = w_out\n",
    "    output['channel'] = c\n",
    "    output['batch_size'] = batch_size\n",
    "    output['data'] = output_data#np.zeros((h_out, w_out, c, batch_size)) # replace with your implementation\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inner_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pooling_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_forward(input_data, layer, param):\n",
    "    \"\"\"\n",
    "    Forward pass for a convolutional layer.\n",
    "\n",
    "    Parameters:\n",
    "    - input_data (dict): A dictionary containing the input data.\n",
    "    - layer (dict): Layer configuration containing parameters such as kernel size, padding, stride, etc.\n",
    "    - param (dict): A dictionary containing the parameters 'b' and 'w'.\n",
    "    \"\"\"\n",
    "    h_in = input_data['height']\n",
    "    w_in = input_data['width']\n",
    "    c = input_data['channel']\n",
    "    batch_size = input_data['batch_size']\n",
    "    k = layer['k']\n",
    "    pad = layer['pad']\n",
    "    stride = layer['stride']\n",
    "    num = layer['num']\n",
    "\n",
    "    # resolve output shape\n",
    "    h_out = (h_in + 2*pad - k) // stride + 1\n",
    "    w_out = (w_in + 2*pad - k) // stride + 1\n",
    "\n",
    "    assert h_out == int(h_out), 'h_out is not integer'\n",
    "    assert w_out == int(w_out), 'w_out is not integer'\n",
    "\n",
    "    input_n = {\n",
    "        'height': h_in,\n",
    "        'width': w_in,\n",
    "        'channel': c,\n",
    "        'data': input_data['data'],\n",
    "        'batch_size': batch_size\n",
    "    }\n",
    "\n",
    "    ############# Fill in the code here ###############\n",
    "    # Hint: use im2col_conv_batch for faster computation\n",
    "    \n",
    "    #empty output_data\n",
    "    output_data = np.zeros((h_out*w_out*num,batch_size))\n",
    "    \n",
    "    #declare empty output to be filled in\n",
    "    conv_img = np.zeros((num,h_out,w_out))\n",
    "    \n",
    "    #prepare the data for convolution\n",
    "    pre_conv = im2col_conv_batch(input_n, layer, h_out, w_out)\n",
    "    \n",
    "    #learning parameters\n",
    "    W = param['w']\n",
    "    b = param['b']\n",
    "    \n",
    "    for batch in range(batch_size):\n",
    "        #grab per image of batch\n",
    "        pre_conv_img = pre_conv[:,:,batch]\n",
    "\n",
    "        #convolving over the number of filters\n",
    "        for n in range(num):\n",
    "            for row in range(h_out):\n",
    "                for col in range(w_out):\n",
    "                    conv_img[n,row,col] = np.dot(pre_conv_img[:,row*w_out+col], W[:,n]) + b[n]\n",
    "                                \n",
    "        output_data[:,batch] = conv_img.reshape(1,h_out*w_out*num)\n",
    "    \n",
    "    output = {\n",
    "        'height': h_out,\n",
    "        'width': w_out,\n",
    "        'channel': num,\n",
    "        'batch_size': batch_size,\n",
    "        'data': output_data#np.zeros((h_out, w_out, num, batch_size)) # replace 'data' value with your implementation\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conv_1():\n",
    "    # Initialize the 'input' structure\n",
    "    input_data = {}\n",
    "    input_data['data'] = np.zeros((25, 2))\n",
    "    input_data['data'][12, 0] = 1\n",
    "    input_data['data'][13, 1] = 1\n",
    "    input_data['width'] = 5\n",
    "    input_data['height'] = 5\n",
    "    input_data['channel'] = 1\n",
    "    input_data['batch_size'] = 2\n",
    "\n",
    "    # Initialize the 'conv_layer' structure\n",
    "    conv_layer = {}\n",
    "    conv_layer['type'] = 'CONV'\n",
    "    conv_layer['num'] = 3\n",
    "    conv_layer['k'] = 5\n",
    "    conv_layer['stride'] = 1\n",
    "    conv_layer['pad'] = 2\n",
    "\n",
    "    # Initialize the 'params' structure\n",
    "    params = {}\n",
    "    params['w'] = np.zeros((25, 3))\n",
    "    params['w'][13, 0] = 0.5  # move image left by one pixel on red channel\n",
    "    params['w'][11+5, 2] = 0.5  # move image top-right dir on blue channel\n",
    "    params['b'] = np.array([0.25, 0.0, 0.25])\n",
    "\n",
    "    # Call the conv_layer_forward function (you would need to define this function in Python)\n",
    "    output = conv_layer_forward(input_data, conv_layer, params)\n",
    "\n",
    "    # Call the display_results function (you would need to define this function in Python)\n",
    "    display_results(input_data, output, 'Convolution Test 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_conv_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conv_2():\n",
    "    # Initialize the 'input' structure\n",
    "    input_data = {}\n",
    "    input_data['data'] = np.zeros((75, 4))\n",
    "\n",
    "    input_data['data'][12, 0] = 1\n",
    "    input_data['data'][12+25, 1] = 1\n",
    "    input_data['data'][13+50, 2] = 1\n",
    "\n",
    "    input_data['data'][0, 3] = 1\n",
    "    input_data['data'][21, 3] = 1\n",
    "    input_data['data'][12, 3] = 1\n",
    "    input_data['data'][13, 3] = 1\n",
    "    input_data['data'][13+25, 3] = 1\n",
    "    input_data['data'][14+25, 3] = 1\n",
    "    input_data['data'][24+50, 3] = 1\n",
    "\n",
    "    input_data['width'] = 5\n",
    "    input_data['height'] = 5\n",
    "    input_data['channel'] = 3\n",
    "    input_data['batch_size'] = 4\n",
    "\n",
    "    # Initialize the 'conv_layer' structure\n",
    "    conv_layer = {}\n",
    "    conv_layer['type'] = 'CONV'\n",
    "    conv_layer['num'] = 3\n",
    "    conv_layer['k'] = 5\n",
    "    conv_layer['stride'] = 1\n",
    "    conv_layer['pad'] = 2\n",
    "\n",
    "    # Initialize the 'params' structure\n",
    "    params = {}\n",
    "    params['w'] = np.zeros((75, 3))\n",
    "    # What it does to red\n",
    "    params['w'][13, 0] = 1.  # move image left by one pixel on red channel\n",
    "    params['w'][11+5, 2] = 1.  # move image top-right dir on blue channel\n",
    "    # What it does to green\n",
    "    params['w'][12+25, 2] = 1.  # stay in place on blue\n",
    "    params['w'][12+5+25, 1] = 1.    # move top on green\n",
    "    # What it does to blue\n",
    "    params['w'][12+50, 0] = 1.0  # stay in place\n",
    "    params['w'][12+50, 1] = 1.0  # stay in place\n",
    "    params['w'][12+50, 2] = 1.0  # stay in place\n",
    "    # Bias\n",
    "    params['b'] = np.array([0., 0.0, 0.])\n",
    "\n",
    "    # Call the conv_layer_forward function (you would need to define this function in Python)\n",
    "    output = conv_layer_forward(input_data, conv_layer, params)\n",
    "\n",
    "    # Call the display_results function (you would need to define this function in Python)\n",
    "    display_results(input_data, output, 'Convolution Test 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_conv_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from load_mnist import load_mnist\n",
    "from init_convnet import init_convnet\n",
    "from conv_net import conv_net\n",
    "from utils import sgd_momentum, get_lr, get_lenet\n",
    "import copy\n",
    "from scipy.io import savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "np.random.seed(100000)\n",
    "\n",
    "# Network definition\n",
    "layers = get_lenet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "fullset = False\n",
    "xtrain, ytrain, xvalidate, yvalidate, xtest, ytest = load_mnist(fullset)\n",
    "xtrain = np.hstack((xtrain, xvalidate))\n",
    "ytrain = np.hstack((ytrain, yvalidate))\n",
    "m_train = xtrain.shape[1]\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters initialization\n",
    "mu = 0.9\n",
    "epsilon = 0.01\n",
    "gamma = 0.0001\n",
    "power = 0.75\n",
    "weight_decay = 0.0005\n",
    "w_lr = 1\n",
    "b_lr = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_interval = 500\n",
    "display_interval = 50\n",
    "snapshot = 500\n",
    "max_iter = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following to train from scratch\n",
    "params = init_convnet(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_winc = copy.deepcopy(params)\n",
    "\n",
    "# Training the network\n",
    "new_order = np.random.permutation(m_train)\n",
    "xtrain = xtrain[:, new_order]\n",
    "ytrain = ytrain[:, new_order]\n",
    "curr_batch = 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "if curr_batch >= m_train:\n",
    "    new_order = np.random.permutation(m_train)\n",
    "    xtrain = xtrain[:, new_order]\n",
    "    ytrain = ytrain[:, new_order]\n",
    "    curr_batch = 0\n",
    "\n",
    "x_batch = xtrain[:, curr_batch:curr_batch+batch_size]\n",
    "y_batch = ytrain[:, curr_batch:curr_batch+batch_size]\n",
    "curr_batch += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from conv_layer import conv_layer_forward, conv_layer_backward\n",
    "from pooling_layer import pooling_layer_forward, pooling_layer_backward\n",
    "from inner_product import inner_product_forward, inner_product_backward\n",
    "from relu import relu_forward, relu_backward\n",
    "from mlrloss import mlrloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cp, param_grad = conv_net(params, layers, x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(layers)\n",
    "batch_size = layers[0]['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(layers)\n",
    "assert layers[0]['type'] == 'DATA', 'first layer must be data layer'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = x_batch\n",
    "output = [{}]\n",
    "output[0]['data'] = data\n",
    "output[0]['height'] = layers[0]['height']\n",
    "output[0]['width'] = layers[0]['width']\n",
    "output[0]['channel'] = layers[0]['channel']\n",
    "output[0]['batch_size'] = layers[0]['batch_size']\n",
    "output[0]['diff'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual conv forward\n",
    "\n",
    "from utils import im2col_conv, col2im_conv, im2col_conv_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_data = output[0]\n",
    "layer=layers[1]\n",
    "param = params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9372/3496402851.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv_layer_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cmpt412/project1/python/conv_layer.py\u001b[0m in \u001b[0;36mconv_layer_forward\u001b[0;34m(input_data, layer, param)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                     \u001b[0mconv_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_conv_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_out\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0moutput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_out\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_out\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "conv_layer_forward(input_data,layer,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "h_in = input_data['height']\n",
    "w_in = input_data['width']\n",
    "c = input_data['channel']\n",
    "batch_size = input_data['batch_size']\n",
    "k = layer['k']\n",
    "pad = layer['pad']\n",
    "stride = layer['stride']\n",
    "num = layer['num']\n",
    "\n",
    "print(h_in)\n",
    "print(w_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# resolve output shape\n",
    "h_out = (h_in + 2*pad - k) // stride + 1\n",
    "w_out = (w_in + 2*pad - k) // stride + 1\n",
    "\n",
    "print(h_out)\n",
    "print(w_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert h_out == int(h_out), 'h_out is not integer'\n",
    "assert w_out == int(w_out), 'w_out is not integer'\n",
    "\n",
    "input_n = {\n",
    "    'height': h_in,\n",
    "    'width': w_in,\n",
    "    'channel': c,\n",
    "    'data': input_data['data'],\n",
    "    'batch_size': batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 24, 24)\n"
     ]
    }
   ],
   "source": [
    "#empty output_data\n",
    "output_data = np.zeros((h_out*w_out*num,batch_size))\n",
    "\n",
    "#declare empty output to be filled in\n",
    "conv_img = np.zeros((num,h_out,w_out))\n",
    "print(conv_img.shape)\n",
    "\n",
    "#prepare the data for convolution\n",
    "pre_conv = im2col_conv_batch(input_n, layer, h_out, w_out)\n",
    "\n",
    "#learning parameters\n",
    "W = param['w']\n",
    "b = param['b']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in range(batch_size):\n",
    "    #grab per image of batch\n",
    "# batch = 0\n",
    "\n",
    "    pre_conv_img = pre_conv[:,:,batch]\n",
    "\n",
    "    #convolving over the number of filters\n",
    "    for n in range(num):\n",
    "        # print(\"n={}\".format(n))\n",
    "        for row in range(h_out):\n",
    "            # print(row)\n",
    "            for col in range(w_out):\n",
    "                conv_img[n,row,col] = np.dot(pre_conv_img[:,row*w_out+col], W[:,n]) + b[:,n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data[:,batch] = conv_img.reshape(1,h_out*w_out*num)\n",
    "\n",
    "test_out = {\n",
    "        'height': h_out,\n",
    "        'width': w_out,\n",
    "        'channel': num,\n",
    "        'batch_size': batch_size,\n",
    "        'data': output_data#np.zeros((h_out, w_out, num, batch_size)) # replace 'data' value with your implementation\n",
    "    }\n",
    "\n",
    "output.append(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_type = layers[1]['type']\n",
    "if layer_type == 'CONV':\n",
    "    output.append(conv_layer_forward(output[0], layers[i], params[i-1]))\n",
    "elif layer_type == 'POOLING':\n",
    "    output.append(pooling_layer_forward(output[i-1], layers[i]))\n",
    "elif layer_type == 'IP':\n",
    "    output.append(inner_product_forward(output[i-1], layers[i], params[i-1]))\n",
    "elif layer_type == 'RELU':\n",
    "    output.append(relu_forward(output[i-1]))\n",
    "else:\n",
    "    raise Exception('Invalid layer type: %s' % layer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below here is the test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9372/1964135126.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mlayer_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'CONV'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_layer_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlayer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'POOLING'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooling_layer_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cmpt412/project1/python/conv_layer.py\u001b[0m in \u001b[0;36mconv_layer_forward\u001b[0;34m(input_data, layer, param)\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                     \u001b[0mconv_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_conv_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_out\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# output_data[:,batch] = conv_img.reshape(1,h_out*w_out*num)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "for i in range(1, l-1):\n",
    "    layer_type = layers[i]['type']\n",
    "    if layer_type == 'CONV':\n",
    "        output.append(conv_layer_forward(output[i-1], layers[i], params[i-1]))\n",
    "    elif layer_type == 'POOLING':\n",
    "        output.append(pooling_layer_forward(output[i-1], layers[i]))\n",
    "    elif layer_type == 'IP':\n",
    "        output.append(inner_product_forward(output[i-1], layers[i], params[i-1]))\n",
    "    elif layer_type == 'RELU':\n",
    "        output.append(relu_forward(output[i-1]))\n",
    "    else:\n",
    "        raise Exception('Invalid layer type: %s' % layer_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RELU Test Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data\n",
    "input_data = {}\n",
    "input_data['data'] = np.zeros((75, 4))\n",
    "\n",
    "input_data['data'][12, 0] = 1\n",
    "input_data['data'][12+25, 1] = 1\n",
    "input_data['data'][13+50, 2] = 1\n",
    "\n",
    "input_data['data'][0, 3] = 1\n",
    "input_data['data'][21, 3] = 1\n",
    "input_data['data'][12, 3] = 1\n",
    "input_data['data'][13, 3] = 1\n",
    "input_data['data'][13+25, 3] = 1\n",
    "input_data['data'][14+25, 3] = 1\n",
    "input_data['data'][24+50, 3] = 1\n",
    "\n",
    "input_data['width'] = 5\n",
    "input_data['height'] = 5\n",
    "input_data['channel'] = 3\n",
    "input_data['batch_size'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    'height': input_data['height'], \n",
    "    'width': input_data['width'],\n",
    "    'channel': input_data['channel'],\n",
    "    'batch_size': input_data['batch_size'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(x):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_activate = np.vectorize(activate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['data'] = relu_activate(input_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagate Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the 'input' structure\n",
    "input_data = {}\n",
    "input_data['data'] = np.zeros((25,2))\n",
    "input_data['data'] = input_data['data'].T\n",
    "input_data['data'].flat[5::3] = 1.0\n",
    "input_data['data'].flat[6::3] = 0.5\n",
    "input_data['data'] = input_data['data'].T\n",
    "input_data['height'] = 25\n",
    "input_data['width'] = 1\n",
    "input_data['channel'] = 1\n",
    "input_data['batch_size'] = 2\n",
    "\n",
    "# Initialize the 'layer' structure\n",
    "layer = {}\n",
    "layer['type'] = 'IP'\n",
    "layer['num'] = 25\n",
    "\n",
    "# Initialize the 'params' structure\n",
    "params = {}\n",
    "params['w'] = np.eye(25)\n",
    "params['w'].flat[:25*10] = 0\n",
    "params['w'][1, 4] = 0.5\n",
    "params['w'][2, 3] = 0.5\n",
    "params['b'] = np.zeros((1,25))\n",
    "params['b'][0,1] = 0.5\n",
    "params['b'][0,3] = 0.5\n",
    "\n",
    "output = inner_product_forward(input_data, layer, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data['data'].shape #this is representing 2 5x5 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['w'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['b'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The calling line\n",
    "pg, input_od = inner_product_backward(output[i], output[i-1], layers[i], params[i-1])\n",
    "\n",
    "We can assume the input_data here is the output from the previous layer for testing\n",
    "\n",
    "layers is just defining properties of the layers but is not important for backpropagation I think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.zeros_like(params['w'])\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the 'input' structure\n",
    "input_data = {}\n",
    "input_data['data'] = np.zeros((75, 4))\n",
    "\n",
    "input_data['data'][12, 0] = 1\n",
    "input_data['data'][12+25, 1] = 1\n",
    "input_data['data'][13+50, 2] = 1\n",
    "\n",
    "input_data['data'][0, 3] = 1\n",
    "input_data['data'][21, 3] = 1\n",
    "input_data['data'][12, 3] = 1\n",
    "input_data['data'][13, 3] = 1\n",
    "input_data['data'][13+25, 3] = 1\n",
    "input_data['data'][14+25, 3] = 1\n",
    "input_data['data'][24+50, 3] = 1\n",
    "\n",
    "input_data['width'] = 5\n",
    "input_data['height'] = 5\n",
    "input_data['channel'] = 3\n",
    "input_data['batch_size'] = 4\n",
    "\n",
    "# Initialize the 'conv_layer' structure\n",
    "conv_layer = {}\n",
    "conv_layer['type'] = 'CONV'\n",
    "conv_layer['num'] = 3\n",
    "conv_layer['k'] = 5\n",
    "conv_layer['stride'] = 1\n",
    "conv_layer['pad'] = 2\n",
    "\n",
    "# Initialize the 'params' structure\n",
    "params = {}\n",
    "params['w'] = np.zeros((75, 3))\n",
    "# What it does to red\n",
    "params['w'][13, 0] = 1.  # move image left by one pixel on red channel\n",
    "params['w'][11+5, 2] = 1.  # move image top-right dir on blue channel\n",
    "# What it does to green\n",
    "params['w'][12+25, 2] = 1.  # stay in place on blue\n",
    "params['w'][12+5+25, 1] = 1.    # move top on green\n",
    "# What it does to blue\n",
    "params['w'][12+50, 0] = 1.0  # stay in place\n",
    "params['w'][12+50, 1] = 1.0  # stay in place\n",
    "params['w'][12+50, 2] = 1.0  # stay in place\n",
    "# Bias\n",
    "params['b'] = np.array([0., 0.0, 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = conv_layer\n",
    "input_data = input_data\n",
    "param = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from forward_conv_layer function\n",
    "h_in = input_data['height']\n",
    "w_in = input_data['width']\n",
    "c = input_data['channel']\n",
    "batch_size = input_data['batch_size']\n",
    "k = layer['k']\n",
    "pad = layer['pad']\n",
    "stride = layer['stride']\n",
    "num = layer['num']\n",
    "\n",
    "# resolve output shape\n",
    "h_out = (h_in + 2*pad - k) // stride + 1\n",
    "w_out = (w_in + 2*pad - k) // stride + 1\n",
    "\n",
    "assert h_out == int(h_out), 'h_out is not integer'\n",
    "assert w_out == int(w_out), 'w_out is not integer'\n",
    "\n",
    "input_n = {\n",
    "    'height': h_in,\n",
    "    'width': w_in,\n",
    "    'channel': c,\n",
    "    'data': input_data['data'],\n",
    "    'batch_size': batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_conv = im2col_conv_batch(input_n, layer, h_out, w_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the above function does is slide the kernel mask around and grab all the relevant pixels that will be used in the convolution and create a bunch of columns that will make up an array for the image. \n",
    "\n",
    "Convolution can easily be performed across the columns and populate a 5x5 across the depth of the filters, given by the 'num' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_conv[:,:,1] #the output of this agrees with what I should be seeing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the 5x5 image for a batch of 2 converted into columns for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare empty output to be filled in\n",
    "conv_img = np.zeros((num,h_out,w_out))\n",
    "output_data = np.zeros((h_out*w_out*num,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_img.shape #this is the convolved image to a depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data.shape #this is the convolved images arranged as column vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = param['w']\n",
    "b = param['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#original loop\n",
    "for batch in range(batch_size):\n",
    "    #grab per image of batch\n",
    "    pre_conv_img = pre_conv[:,:,batch]\n",
    "\n",
    "    #convolving over the number of filters\n",
    "    for n in range(num):\n",
    "        for row in range(h_out):\n",
    "            for col in range(w_out): \n",
    "                conv_img[n,row,col] = np.dot(pre_conv_img[row*5+col].T, W[:,n]) #+ b[n]\n",
    "\n",
    "#     output_data[:,batch] = conv_img.reshape(1,h_out*w_out*num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_conv_img = pre_conv[:,:,1]\n",
    "\n",
    "#convolving over the number of filters\n",
    "for n in range(num):\n",
    "    for row in range(h_out):\n",
    "        for col in range(w_out): \n",
    "            conv_img[n,row,col] = np.dot(pre_conv_img[row*5+col], W[:,n]) + b[n]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pre_conv[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[:,0].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(input_data['batch_size'], 2)\n",
    "for batch in range(input_data['batch_size']):\n",
    "#         # outputs\n",
    "#         img1 = output['data'][:,batch].reshape(output['channel'], output['height'], output['width'])\n",
    "#         img1 = np.transpose(img1, (1, 2, 0))\n",
    "#         ax[batch, 1].imshow(img1)\n",
    "#         ax[batch, 1].set_title(f'Output {batch + 1}')\n",
    "#         ax[batch, 1].set_axis_off()\n",
    "\n",
    "    # inputs\n",
    "    imgin1 = input_data['data'][:,batch].reshape(input_data['channel'], input_data['height'], input_data['width'])\n",
    "    imgin1 = np.transpose(imgin1, (1, 2, 0))\n",
    "    ax[batch, 0].imshow(imgin1)\n",
    "    ax[batch, 0].set_title(f'Input {batch + 1}')\n",
    "    ax[batch, 0].set_axis_off()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
    "print(arr)\n",
    "\n",
    "#2D slicing\n",
    "mtx = arr[:2, 1:4]\n",
    "\n",
    "print(mtx)\n",
    "\n",
    "\n",
    "print(mtx.shape)\n",
    "\n",
    "ar = mtx.reshape(1,mtx.shape[0]*mtx.shape[1])[0]\n",
    "\n",
    "print(ar)\n",
    "\n",
    "print(np.max(mtx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = input_data['data'][:,0].reshape(c, h_in, w_in)[2]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_test = np.pad(test,1)\n",
    "pad_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_img = np.zeros((c,pad*2+h_in,pad*2+w_in))\n",
    "pad_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chan in range(c):\n",
    "    pad_img[chan] = np.pad(img[chan],pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,pad_img.shape[1],stride): #stride is 2\n",
    "        \n",
    "        #go across columns with i\n",
    "        for i in range(0,pad_img.shape[2], stride):\n",
    "            print(j,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
