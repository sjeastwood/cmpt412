{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from utils import im2col_conv, col2im_conv, im2col_conv_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLOBALS\n",
    "resultsdir = '../results'\n",
    "os.makedirs(resultsdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results_2(input_data, output, params, testname):\n",
    "    global resultsdir\n",
    "    \n",
    "    fig, ax = plt.subplots(input_data['batch_size'], 1)\n",
    "    for batch in range(input_data['batch_size']):\n",
    "        # outputs\n",
    "        img = output['data'][:,batch].reshape(output['height'], output['width'])\n",
    "        \n",
    "        # middle\n",
    "        img = np.hstack([params['w'].T, np.ones(img.shape), params['b'].reshape(-1, 1), np.zeros(img.shape), img])\n",
    "        \n",
    "        # inputs\n",
    "        imgin = input_data['data'][:,batch].reshape(input_data['height'], input_data['width']).T\n",
    "        imgin_padded = np.hstack([imgin, np.zeros((imgin.shape[0], 4))])\n",
    "        img = np.vstack([imgin_padded, np.zeros(imgin_padded.shape), np.zeros(imgin_padded.shape), np.ones(imgin_padded.shape), img])\n",
    "        \n",
    "        ax[batch].imshow(img)\n",
    "        ax[batch].set_title(f'Batch {batch + 1}')\n",
    "        ax[batch].set_axis_off()\n",
    "        \n",
    "    fig.suptitle(testname)\n",
    "    \n",
    "    filename = f\"{resultsdir}/{testname}.png\"\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner_product_forward(input, layer, param):\n",
    "    \"\"\"\n",
    "    Forward pass of inner product layer.\n",
    "\n",
    "    Parameters:\n",
    "    - input (dict): Contains the input data.\n",
    "    - layer (dict): Contains the configuration for the inner product layer.\n",
    "    - param (dict): Contains the weights and biases for the inner product layer.\n",
    "    \"\"\"\n",
    "\n",
    "    d, k = input[\"data\"].shape\n",
    "    n = param[\"w\"].shape[1]\n",
    "\n",
    "    ###### Fill in the code here ######\n",
    "    W = param[\"w\"]\n",
    "    X = input[\"data\"]\n",
    "    b = param[\"b\"]\n",
    "    \n",
    "    f = np.dot(W.T,X) + b.T\n",
    "    \n",
    "    # Initialize output data structure\n",
    "    output = {\n",
    "        \"height\": n,\n",
    "        \"width\": 1,\n",
    "        \"channel\": 1,\n",
    "        \"batch_size\": k,\n",
    "        \"data\": f #np.zeros((n, k)) # replace 'data' value with your implementation\n",
    "    }\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inner_1():\n",
    "    # Initialize the 'input' structure\n",
    "    input_data = {}\n",
    "    input_data['data'] = np.zeros((25,2))\n",
    "    input_data['data'] = input_data['data'].T\n",
    "    input_data['data'].flat[5::3] = 1.0\n",
    "    input_data['data'].flat[6::3] = 0.5\n",
    "    input_data['data'] = input_data['data'].T\n",
    "    input_data['height'] = 25\n",
    "    input_data['width'] = 1\n",
    "    input_data['channel'] = 1\n",
    "    input_data['batch_size'] = 2\n",
    "\n",
    "    # Initialize the 'layer' structure\n",
    "    layer = {}\n",
    "    layer['type'] = 'IP'\n",
    "    layer['num'] = 25\n",
    "\n",
    "    # Initialize the 'params' structure\n",
    "    params = {}\n",
    "    params['w'] = np.eye(25)\n",
    "    params['w'].flat[:25*10] = 0\n",
    "    params['w'][1, 4] = 0.5\n",
    "    params['w'][2, 3] = 0.5\n",
    "    params['b'] = np.zeros((1,25))\n",
    "    params['b'][0,1] = 0.5\n",
    "    params['b'][0,3] = 0.5\n",
    "\n",
    "    output = inner_product_forward(input_data, layer, params)\n",
    "\n",
    "    display_results_2(input_data, output, params, 'Inner Product Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pooling_1():\n",
    "    input_data = {'data': np.zeros((36*3,2))}\n",
    "    input_data['data'][12, 0] = 0.5\n",
    "    input_data['data'][13, 0] = 0.25\n",
    "    input_data['data'][14, 0] = 0.5\n",
    "    input_data['data'][19+72, 0] = 0.75\n",
    "\n",
    "    input_data['data'][14, 1] = 0.25\n",
    "    input_data['data'][15, 1] = 0.75\n",
    "    input_data['data'][5+36, 1] = 0.75\n",
    "    input_data['data'][11+72, 1] = 0.75\n",
    "    input_data['width'] = 6\n",
    "    input_data['height'] = 6\n",
    "    input_data['channel'] = 3\n",
    "    input_data['batch_size'] = 2\n",
    "\n",
    "    layer = {'type': 'POOLING', 'k': 2, 'stride': 2, 'pad': 0}\n",
    "\n",
    "    output = pooling_layer_forward(input_data, layer)\n",
    "    display_results(input_data, output, 'Pooling Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(input_data, output, testname):\n",
    "    global resultsdir\n",
    "    \n",
    "    fig, ax = plt.subplots(input_data['batch_size'], 2)\n",
    "    for batch in range(input_data['batch_size']):\n",
    "        # outputs\n",
    "        img1 = output['data'][:,batch].reshape(output['channel'], output['height'], output['width'])\n",
    "        img1 = np.transpose(img1, (1, 2, 0))\n",
    "        ax[batch, 1].imshow(img1)\n",
    "        ax[batch, 1].set_title(f'Output {batch + 1}')\n",
    "        ax[batch, 1].set_axis_off()\n",
    "\n",
    "        # inputs\n",
    "        imgin1 = input_data['data'][:,batch].reshape(input_data['channel'], input_data['height'], input_data['width'])\n",
    "        imgin1 = np.transpose(imgin1, (1, 2, 0))\n",
    "        ax[batch, 0].imshow(imgin1)\n",
    "        ax[batch, 0].set_title(f'Input {batch + 1}')\n",
    "        ax[batch, 0].set_axis_off()\n",
    "\n",
    "    fig.suptitle(testname)\n",
    "    \n",
    "    filename = f\"{resultsdir}/{testname}.png\"\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_layer_forward(input, layer):\n",
    "    \"\"\"\n",
    "    Forward pass for the pooling layer.\n",
    "\n",
    "    Parameters:\n",
    "    - input (dict): Contains the input data.\n",
    "    - layer (dict): Layer configuration containing parameters such as kernel size, padding, stride, etc.\n",
    "    \"\"\"\n",
    "    \n",
    "    h_in = input['height']\n",
    "    w_in = input['width']\n",
    "    c = input['channel']\n",
    "    batch_size = input['batch_size']\n",
    "    k = layer['k']\n",
    "    pad = layer['pad']\n",
    "    stride = layer['stride']\n",
    "\n",
    "    h_out = int((h_in + 2 * pad - k) / stride + 1)\n",
    "    w_out = int((w_in + 2 * pad - k) / stride + 1)\n",
    "    \n",
    "    ###### Fill in the code here ######\n",
    "    output_data = np.zeros((c*h_out*w_out,batch_size))\n",
    "\n",
    "    for batch in range(batch_size):\n",
    "        #input image reshaped\n",
    "        img = input['data'][:,batch].reshape(c, h_in, w_in) #need to account for padding\n",
    "\n",
    "        # add padding if it exists\n",
    "        pad_img = np.zeros((c,pad*2+h_in,pad*2+w_in))\n",
    "        for chan in range(c):\n",
    "            pad_img[chan] = np.pad(img[chan],pad)\n",
    "\n",
    "        #matrix to hold the pooled layers\n",
    "        pool_mtx = np.zeros((c,h_out,w_out))\n",
    "\n",
    "        #slide kernel across pad_img and grab max\n",
    "\n",
    "        row = 0\n",
    "        col = 0 #to control the pool_mtx row and col to be filled in\n",
    "        #go across rows with j\n",
    "        for j in range(0,pad_img.shape[1],stride): #stride is 2\n",
    "\n",
    "            col = 0 #reset column for next row\n",
    "\n",
    "            #go across columns with i\n",
    "            for i in range(0,pad_img.shape[2],stride):\n",
    "\n",
    "                #go across channels\n",
    "                for chan in range(c):\n",
    "                    #grab max from the kernel slice of image mtx\n",
    "                    pool_mtx[chan,row,col] = np.max(pad_img[chan,j:j+stride,i:i+stride])\n",
    "\n",
    "                col = col + 1 # move on to the next coumn\n",
    "\n",
    "            row = row + 1 # increment row when columns are done\n",
    "\n",
    "        output_data[:,batch] = pool_mtx.reshape(1,c*h_out*w_out)[0]\n",
    "    \n",
    "    output = {}\n",
    "    output['height'] = h_out\n",
    "    output['width'] = w_out\n",
    "    output['channel'] = c\n",
    "    output['batch_size'] = batch_size\n",
    "    output['data'] = output_data#np.zeros((h_out, w_out, c, batch_size)) # replace with your implementation\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_inner_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_pooling_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer_forward(input_data, layer, param):\n",
    "    \"\"\"\n",
    "    Forward pass for a convolutional layer.\n",
    "\n",
    "    Parameters:\n",
    "    - input_data (dict): A dictionary containing the input data.\n",
    "    - layer (dict): Layer configuration containing parameters such as kernel size, padding, stride, etc.\n",
    "    - param (dict): A dictionary containing the parameters 'b' and 'w'.\n",
    "    \"\"\"\n",
    "    h_in = input_data['height']\n",
    "    w_in = input_data['width']\n",
    "    c = input_data['channel']\n",
    "    batch_size = input_data['batch_size']\n",
    "    k = layer['k']\n",
    "    pad = layer['pad']\n",
    "    stride = layer['stride']\n",
    "    num = layer['num']\n",
    "\n",
    "    # resolve output shape\n",
    "    h_out = (h_in + 2*pad - k) // stride + 1\n",
    "    w_out = (w_in + 2*pad - k) // stride + 1\n",
    "\n",
    "    assert h_out == int(h_out), 'h_out is not integer'\n",
    "    assert w_out == int(w_out), 'w_out is not integer'\n",
    "\n",
    "    input_n = {\n",
    "        'height': h_in,\n",
    "        'width': w_in,\n",
    "        'channel': c,\n",
    "        'data': input_data['data'],\n",
    "        'batch_size': batch_size\n",
    "    }\n",
    "\n",
    "    ############# Fill in the code here ###############\n",
    "    # Hint: use im2col_conv_batch for faster computation\n",
    "    \n",
    "    #empty output_data\n",
    "    output_data = np.zeros((h_out*w_out*num,batch_size))\n",
    "    \n",
    "    #declare empty output to be filled in\n",
    "    conv_img = np.zeros((num,h_out,w_out))\n",
    "    \n",
    "    #prepare the data for convolution\n",
    "    pre_conv = im2col_conv_batch(input_n, layer, h_out, w_out)\n",
    "    \n",
    "    #learning parameters\n",
    "    W = param['w']\n",
    "    b = param['b']\n",
    "    \n",
    "    for batch in range(batch_size):\n",
    "        #grab per image of batch\n",
    "        pre_conv_img = pre_conv[:,:,batch]\n",
    "\n",
    "        #convolving over the number of filters\n",
    "        for n in range(num):\n",
    "            for row in range(h_out):\n",
    "                for col in range(w_out):\n",
    "                    conv_img[n,row,col] = np.dot(pre_conv_img[:,row*w_out+col], W[:,n]) + b[n]\n",
    "                                \n",
    "        output_data[:,batch] = conv_img.reshape(1,h_out*w_out*num)\n",
    "    \n",
    "    output = {\n",
    "        'height': h_out,\n",
    "        'width': w_out,\n",
    "        'channel': num,\n",
    "        'batch_size': batch_size,\n",
    "        'data': output_data#np.zeros((h_out, w_out, num, batch_size)) # replace 'data' value with your implementation\n",
    "    }\n",
    "    \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conv_1():\n",
    "    # Initialize the 'input' structure\n",
    "    input_data = {}\n",
    "    input_data['data'] = np.zeros((25, 2))\n",
    "    input_data['data'][12, 0] = 1\n",
    "    input_data['data'][13, 1] = 1\n",
    "    input_data['width'] = 5\n",
    "    input_data['height'] = 5\n",
    "    input_data['channel'] = 1\n",
    "    input_data['batch_size'] = 2\n",
    "\n",
    "    # Initialize the 'conv_layer' structure\n",
    "    conv_layer = {}\n",
    "    conv_layer['type'] = 'CONV'\n",
    "    conv_layer['num'] = 3\n",
    "    conv_layer['k'] = 5\n",
    "    conv_layer['stride'] = 1\n",
    "    conv_layer['pad'] = 2\n",
    "\n",
    "    # Initialize the 'params' structure\n",
    "    params = {}\n",
    "    params['w'] = np.zeros((25, 3))\n",
    "    params['w'][13, 0] = 0.5  # move image left by one pixel on red channel\n",
    "    params['w'][11+5, 2] = 0.5  # move image top-right dir on blue channel\n",
    "    params['b'] = np.array([0.25, 0.0, 0.25])\n",
    "\n",
    "    # Call the conv_layer_forward function (you would need to define this function in Python)\n",
    "    output = conv_layer_forward(input_data, conv_layer, params)\n",
    "\n",
    "    # Call the display_results function (you would need to define this function in Python)\n",
    "    display_results(input_data, output, 'Convolution Test 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_conv_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_conv_2():\n",
    "    # Initialize the 'input' structure\n",
    "    input_data = {}\n",
    "    input_data['data'] = np.zeros((75, 4))\n",
    "\n",
    "    input_data['data'][12, 0] = 1\n",
    "    input_data['data'][12+25, 1] = 1\n",
    "    input_data['data'][13+50, 2] = 1\n",
    "\n",
    "    input_data['data'][0, 3] = 1\n",
    "    input_data['data'][21, 3] = 1\n",
    "    input_data['data'][12, 3] = 1\n",
    "    input_data['data'][13, 3] = 1\n",
    "    input_data['data'][13+25, 3] = 1\n",
    "    input_data['data'][14+25, 3] = 1\n",
    "    input_data['data'][24+50, 3] = 1\n",
    "\n",
    "    input_data['width'] = 5\n",
    "    input_data['height'] = 5\n",
    "    input_data['channel'] = 3\n",
    "    input_data['batch_size'] = 4\n",
    "\n",
    "    # Initialize the 'conv_layer' structure\n",
    "    conv_layer = {}\n",
    "    conv_layer['type'] = 'CONV'\n",
    "    conv_layer['num'] = 3\n",
    "    conv_layer['k'] = 5\n",
    "    conv_layer['stride'] = 1\n",
    "    conv_layer['pad'] = 2\n",
    "\n",
    "    # Initialize the 'params' structure\n",
    "    params = {}\n",
    "    params['w'] = np.zeros((75, 3))\n",
    "    # What it does to red\n",
    "    params['w'][13, 0] = 1.  # move image left by one pixel on red channel\n",
    "    params['w'][11+5, 2] = 1.  # move image top-right dir on blue channel\n",
    "    # What it does to green\n",
    "    params['w'][12+25, 2] = 1.  # stay in place on blue\n",
    "    params['w'][12+5+25, 1] = 1.    # move top on green\n",
    "    # What it does to blue\n",
    "    params['w'][12+50, 0] = 1.0  # stay in place\n",
    "    params['w'][12+50, 1] = 1.0  # stay in place\n",
    "    params['w'][12+50, 2] = 1.0  # stay in place\n",
    "    # Bias\n",
    "    params['b'] = np.array([0., 0.0, 0.])\n",
    "\n",
    "    # Call the conv_layer_forward function (you would need to define this function in Python)\n",
    "    output = conv_layer_forward(input_data, conv_layer, params)\n",
    "\n",
    "    # Call the display_results function (you would need to define this function in Python)\n",
    "    display_results(input_data, output, 'Convolution Test 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_conv_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RELU Test Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data\n",
    "input_data = {}\n",
    "input_data['data'] = np.zeros((75, 4))\n",
    "\n",
    "input_data['data'][12, 0] = 1\n",
    "input_data['data'][12+25, 1] = 1\n",
    "input_data['data'][13+50, 2] = 1\n",
    "\n",
    "input_data['data'][0, 3] = 1\n",
    "input_data['data'][21, 3] = 1\n",
    "input_data['data'][12, 3] = 1\n",
    "input_data['data'][13, 3] = 1\n",
    "input_data['data'][13+25, 3] = 1\n",
    "input_data['data'][14+25, 3] = 1\n",
    "input_data['data'][24+50, 3] = 1\n",
    "\n",
    "input_data['width'] = 5\n",
    "input_data['height'] = 5\n",
    "input_data['channel'] = 3\n",
    "input_data['batch_size'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {\n",
    "    'height': input_data['height'], \n",
    "    'width': input_data['width'],\n",
    "    'channel': input_data['channel'],\n",
    "    'batch_size': input_data['batch_size'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(x):\n",
    "    if x > 0:\n",
    "        return x\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_activate = np.vectorize(activate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "output['data'] = relu_activate(input_data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [1, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 0],\n",
       "       [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Testing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the 'input' structure\n",
    "input_data = {}\n",
    "input_data['data'] = np.zeros((75, 4))\n",
    "\n",
    "input_data['data'][12, 0] = 1\n",
    "input_data['data'][12+25, 1] = 1\n",
    "input_data['data'][13+50, 2] = 1\n",
    "\n",
    "input_data['data'][0, 3] = 1\n",
    "input_data['data'][21, 3] = 1\n",
    "input_data['data'][12, 3] = 1\n",
    "input_data['data'][13, 3] = 1\n",
    "input_data['data'][13+25, 3] = 1\n",
    "input_data['data'][14+25, 3] = 1\n",
    "input_data['data'][24+50, 3] = 1\n",
    "\n",
    "input_data['width'] = 5\n",
    "input_data['height'] = 5\n",
    "input_data['channel'] = 3\n",
    "input_data['batch_size'] = 4\n",
    "\n",
    "# Initialize the 'conv_layer' structure\n",
    "conv_layer = {}\n",
    "conv_layer['type'] = 'CONV'\n",
    "conv_layer['num'] = 3\n",
    "conv_layer['k'] = 5\n",
    "conv_layer['stride'] = 1\n",
    "conv_layer['pad'] = 2\n",
    "\n",
    "# Initialize the 'params' structure\n",
    "params = {}\n",
    "params['w'] = np.zeros((75, 3))\n",
    "# What it does to red\n",
    "params['w'][13, 0] = 1.  # move image left by one pixel on red channel\n",
    "params['w'][11+5, 2] = 1.  # move image top-right dir on blue channel\n",
    "# What it does to green\n",
    "params['w'][12+25, 2] = 1.  # stay in place on blue\n",
    "params['w'][12+5+25, 1] = 1.    # move top on green\n",
    "# What it does to blue\n",
    "params['w'][12+50, 0] = 1.0  # stay in place\n",
    "params['w'][12+50, 1] = 1.0  # stay in place\n",
    "params['w'][12+50, 2] = 1.0  # stay in place\n",
    "# Bias\n",
    "params['b'] = np.array([0., 0.0, 0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = conv_layer\n",
    "input_data = input_data\n",
    "param = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from forward_conv_layer function\n",
    "h_in = input_data['height']\n",
    "w_in = input_data['width']\n",
    "c = input_data['channel']\n",
    "batch_size = input_data['batch_size']\n",
    "k = layer['k']\n",
    "pad = layer['pad']\n",
    "stride = layer['stride']\n",
    "num = layer['num']\n",
    "\n",
    "# resolve output shape\n",
    "h_out = (h_in + 2*pad - k) // stride + 1\n",
    "w_out = (w_in + 2*pad - k) // stride + 1\n",
    "\n",
    "assert h_out == int(h_out), 'h_out is not integer'\n",
    "assert w_out == int(w_out), 'w_out is not integer'\n",
    "\n",
    "input_n = {\n",
    "    'height': h_in,\n",
    "    'width': w_in,\n",
    "    'channel': c,\n",
    "    'data': input_data['data'],\n",
    "    'batch_size': batch_size\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_conv = im2col_conv_batch(input_n, layer, h_out, w_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What the above function does is slide the kernel mask around and grab all the relevant pixels that will be used in the convolution and create a bunch of columns that will make up an array for the image. \n",
    "\n",
    "Convolution can easily be performed across the columns and populate a 5x5 across the depth of the filters, given by the 'num' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 25, 4)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_conv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_conv[:,:,1] #the output of this agrees with what I should be seeing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the 5x5 image for a batch of 2 converted into columns for computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare empty output to be filled in\n",
    "conv_img = np.zeros((num,h_out,w_out))\n",
    "output_data = np.zeros((h_out*w_out*num,batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_img.shape #this is the convolved image to a depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data.shape #this is the convolved images arranged as column vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = param['w']\n",
    "b = param['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (25,) and (75,) not aligned: 25 (dim 0) != 75 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(h_out):\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(w_out): \n\u001b[0;32m---> 10\u001b[0m         conv_img[n,row,col] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_conv_img\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (25,) and (75,) not aligned: 25 (dim 0) != 75 (dim 0)"
     ]
    }
   ],
   "source": [
    "#original loop\n",
    "for batch in range(batch_size):\n",
    "    #grab per image of batch\n",
    "    pre_conv_img = pre_conv[:,:,batch]\n",
    "\n",
    "    #convolving over the number of filters\n",
    "    for n in range(num):\n",
    "        for row in range(h_out):\n",
    "            for col in range(w_out): \n",
    "                conv_img[n,row,col] = np.dot(pre_conv_img[row*5+col].T, W[:,n]) #+ b[n]\n",
    "\n",
    "#     output_data[:,batch] = conv_img.reshape(1,h_out*w_out*num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (25,) and (75,) not aligned: 25 (dim 0) != 75 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(h_out):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(w_out): \n\u001b[0;32m----> 7\u001b[0m         conv_img[n,row,col] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_conv_img\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m b[n]\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (25,) and (75,) not aligned: 25 (dim 0) != 75 (dim 0)"
     ]
    }
   ],
   "source": [
    "pre_conv_img = pre_conv[:,:,1]\n",
    "\n",
    "#convolving over the number of filters\n",
    "for n in range(num):\n",
    "    for row in range(h_out):\n",
    "        for col in range(w_out): \n",
    "            conv_img[n,row,col] = np.dot(pre_conv_img[row*5+col], W[:,n]) + b[n]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pre_conv[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:,0].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(input_data['batch_size'], 2)\n",
    "for batch in range(input_data['batch_size']):\n",
    "#         # outputs\n",
    "#         img1 = output['data'][:,batch].reshape(output['channel'], output['height'], output['width'])\n",
    "#         img1 = np.transpose(img1, (1, 2, 0))\n",
    "#         ax[batch, 1].imshow(img1)\n",
    "#         ax[batch, 1].set_title(f'Output {batch + 1}')\n",
    "#         ax[batch, 1].set_axis_off()\n",
    "\n",
    "    # inputs\n",
    "    imgin1 = input_data['data'][:,batch].reshape(input_data['channel'], input_data['height'], input_data['width'])\n",
    "    imgin1 = np.transpose(imgin1, (1, 2, 0))\n",
    "    ax[batch, 0].imshow(imgin1)\n",
    "    ax[batch, 0].set_title(f'Input {batch + 1}')\n",
    "    ax[batch, 0].set_axis_off()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]])\n",
    "print(arr)\n",
    "\n",
    "#2D slicing\n",
    "mtx = arr[:2, 1:4]\n",
    "\n",
    "print(mtx)\n",
    "\n",
    "\n",
    "print(mtx.shape)\n",
    "\n",
    "ar = mtx.reshape(1,mtx.shape[0]*mtx.shape[1])[0]\n",
    "\n",
    "print(ar)\n",
    "\n",
    "print(np.max(mtx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = input_data['data'][:,0].reshape(c, h_in, w_in)[2]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_test = np.pad(test,1)\n",
    "pad_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_img = np.zeros((c,pad*2+h_in,pad*2+w_in))\n",
    "pad_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chan in range(c):\n",
    "    pad_img[chan] = np.pad(img[chan],pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,pad_img.shape[1],stride): #stride is 2\n",
    "        \n",
    "        #go across columns with i\n",
    "        for i in range(0,pad_img.shape[2], stride):\n",
    "            print(j,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
