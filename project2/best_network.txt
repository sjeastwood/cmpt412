# The output of torchvision datasets are PILImage images of range [0, 1].
# Using transforms.ToTensor(), transform them to Tensors of normalized range
# [-1, 1].


# <<TODO#1>> Use transforms.Normalize() with the right parameters to 
# make the data well conditioned (zero mean, std dev=1) for improved training.
# <<TODO#2>> Try using transforms.RandomCrop() and/or transforms.RandomHorizontalFlip()
# to augment training data.
# After your edits, make sure that test_transform should have the same data
# normalization parameters as train_transform
# You shouldn't have any data augmentation in test_transform (val or test data is never augmented).
# ---------------------

train_transform = transforms.Compose(
    [transforms.ToTensor(), 
     transforms.RandomHorizontalFlip(0.5),
#      transforms.RandomVerticalFlip(0.2),
     transforms.RandomCrop(28),
    # transforms.RandomCrop(30),
     transforms.Resize((32,32),antialias=True),
     transforms.RandomRotation(10),
     transforms.RandomPerspective(distortion_scale=0.3,p=0.5), 
     transforms.Normalize((0.5064, 0.4798, 0.4314),(0.2557, 0.2441, 0.2634)),
    ])
test_transform = transforms.Compose(
    [transforms.ToTensor(), 
     transforms.Normalize((0.5064, 0.4798, 0.4314),(0.2557, 0.2441, 0.2634))
    ])
# ---------------------

trainset = CIFAR100_SFU_CV(root=PATH_TO_CIFAR100_SFU_CV, fold="train",
                                        download=True, transform=train_transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=TRAIN_BS,
                                          shuffle=True, num_workers=2)
print("Train set size: "+str(len(trainset)))

valset = CIFAR100_SFU_CV(root=PATH_TO_CIFAR100_SFU_CV, fold="val",
                                       download=True, transform=test_transform)
valloader = torch.utils.data.DataLoader(valset, batch_size=TEST_BS,
                                         shuffle=False, num_workers=2)
print("Val set size: "+str(len(valset)))

testset = CIFAR100_SFU_CV(root=PATH_TO_CIFAR100_SFU_CV, fold="test",
                                       download=True, transform=test_transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=TEST_BS,
                                         shuffle=False, num_workers=2)
print("Test set size: "+str(len(testset)))

# The 100 classes for CIFAR100
classes = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']



--------------------------------------------------------------------------------
import torch.nn as nn
import torch.nn.functional as F

class BaseNet(nn.Module):
    def __init__(self):
        super(BaseNet, self).__init__()

        # <<TODO#3>> Add more conv layers with increasing
        # output channels
        # <<TODO#4>> Add normalization layers after conv
        # layers (nn.BatchNorm2d)

        # Also experiment with kernel size in conv2d layers (say 3
        # inspired from VGGNet)
        # To keep it simple, keep the same kernel size
        # (right now set to 5) in all conv layers.
        # Do not have a maxpool layer after every conv layer in your
        # deeper network as it leads to too much loss of information.

        self.conv1 = nn.Conv2d(3, 20, 3)
        self.norm1 = nn.BatchNorm2d(20)

        self.conv2 = nn.Conv2d(20, 64, 3) 
        self.norm2 = nn.BatchNorm2d(64)

        self.conv3 = nn.Conv2d(64, 128, 3)
        self.norm3 = nn.BatchNorm2d(128)

        self.conv4 = nn.Conv2d(128, 256, 3) 
        self.norm4 = nn.BatchNorm2d(256)

        self.conv5 = nn.Conv2d(256, 512, 3) 
        self.norm5 = nn.BatchNorm2d(512)

        self.conv6 = nn.Conv2d(512, 1024, 3)
        self.norm6 = nn.BatchNorm2d(1024)

        self.pool = nn.MaxPool2d(2, 2)

        # <<TODO#3>> Add more linear (fc) layers
        # <<TODO#4>> Add normalization layers after linear and
        # experiment inserting them before or after ReLU (nn.BatchNorm1d)
        # More on nn.sequential:
        # http://pytorch.org/docs/master/nn.html#torch.nn.Sequential

        self.fc_net = nn.Sequential(

#             nn.Linear(360 * 5 * 5, TOTAL_CLASSES//2), 
            nn.Linear(1024 * 4 * 4, 2048), 
            # nn.Linear(1024*3*3,4096),
            nn.BatchNorm1d(2048),
            nn.ReLU(inplace=True),
            # nn.Dropout1d(p=0.1), 
            nn.Linear(2048, 2048),
            nn.BatchNorm1d(2048),
            nn.ReLU(inplace=True),
            # nn.Dropout1d(p=0.2),
            # nn.Linear(2048, 1024),
            # nn.BatchNorm1d(1024),
            # nn.ReLU(inplace=True),
            # nn.Dropout1d(p=0.1), #0.1
            nn.Linear(2048, TOTAL_CLASSES),
        )

    def forward(self, x):


        #input is coming in with 32x32

        # first convolution 32 -> 30
        # second convolution 30 -> 28
        # third convolution 28 -> 26 
        # fourth convolution 26 -> 24 
        # pooling 24 -> 12

        x = F.relu(self.norm1(self.conv1(x))) #input -> 32 -> 30
        x = F.relu(self.norm2(self.conv2(x))) #30 -> 28 
        x = F.relu(self.norm3(self.conv3(x))) #28 -> 26
        x = self.pool(F.relu(self.norm4(self.conv4(x)))) #26 -> 24 -> 12
        x = self.pool(self.norm6(self.conv6(F.relu(self.norm5(self.conv5(x)))))) #12 -> 10 -> 8 -> 4 -> output

        #trying
        # x = F.relu(self.conv6(x)) # -> makes a 3x3

        #the two convolutions with kernel sizes of 3 lead to
        # convolution 12 -> 10
        # pooling 10 -> 5

        # channel num x output height x output width
        x = x.view(-1, 1024 * 4 * 4)
        # x = x.view(-1, 1024 * 3 * 3)
        x = self.fc_net(x)

        return x

# Create an instance of the nn.module class defined above:
net = BaseNet()

# For training on GPU, we need to transfer net and data onto the GPU
# http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu
if IS_GPU:
    net = net.cuda()