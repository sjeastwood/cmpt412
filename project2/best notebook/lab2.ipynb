{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T05:59:24.841455Z","iopub.status.busy":"2023-10-08T05:59:24.841138Z","iopub.status.idle":"2023-10-08T05:59:24.846194Z","shell.execute_reply":"2023-10-08T05:59:24.844959Z","shell.execute_reply.started":"2023-10-08T05:59:24.841432Z"},"trusted":true},"outputs":[],"source":["import os\n","# input_dir = '/kaggle/input/'\n","work_dir = '/kaggle/working/'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T05:59:25.135052Z","iopub.status.busy":"2023-10-08T05:59:25.134710Z","iopub.status.idle":"2023-10-08T05:59:27.267795Z","shell.execute_reply":"2023-10-08T05:59:27.266417Z","shell.execute_reply.started":"2023-10-08T05:59:25.135026Z"},"trusted":true},"outputs":[],"source":["!cp -r /kaggle/input/sfu-lab2/cifar100/cifar100 /kaggle/working"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T05:59:27.271102Z","iopub.status.busy":"2023-10-08T05:59:27.270488Z","iopub.status.idle":"2023-10-08T06:00:10.708344Z","shell.execute_reply":"2023-10-08T06:00:10.707118Z","shell.execute_reply.started":"2023-10-08T05:59:27.271064Z"},"trusted":true},"outputs":[],"source":["!cp -r /kaggle/input/sfu-lab2/test/test /kaggle/working\n","!cp -r /kaggle/input/sfu-lab2/train/train /kaggle/working"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:00:10.710624Z","iopub.status.busy":"2023-10-08T06:00:10.710273Z","iopub.status.idle":"2023-10-08T06:00:19.358573Z","shell.execute_reply":"2023-10-08T06:00:19.357443Z","shell.execute_reply.started":"2023-10-08T06:00:10.710588Z"},"trusted":true},"outputs":[],"source":["!pip3 install torch torchvision"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:00:19.362490Z","iopub.status.busy":"2023-10-08T06:00:19.361477Z","iopub.status.idle":"2023-10-08T06:00:19.427394Z","shell.execute_reply":"2023-10-08T06:00:19.426431Z","shell.execute_reply.started":"2023-10-08T06:00:19.362454Z"},"trusted":true},"outputs":[],"source":["import torch\n","a = torch.Tensor([1]).cuda()\n","print(a)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:00:19.429396Z","iopub.status.busy":"2023-10-08T06:00:19.428764Z","iopub.status.idle":"2023-10-08T06:00:19.437149Z","shell.execute_reply":"2023-10-08T06:00:19.436231Z","shell.execute_reply.started":"2023-10-08T06:00:19.429365Z"},"trusted":true},"outputs":[],"source":["torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:00:19.439324Z","iopub.status.busy":"2023-10-08T06:00:19.438432Z","iopub.status.idle":"2023-10-08T06:00:19.995485Z","shell.execute_reply":"2023-10-08T06:00:19.994562Z","shell.execute_reply.started":"2023-10-08T06:00:19.439294Z"},"trusted":true},"outputs":[],"source":["\"\"\"Headers\"\"\"\n","\n","from __future__ import print_function\n","from PIL import Image\n","import os\n","import os.path\n","import numpy as np\n","import sys\n","if sys.version_info[0] == 2:\n","    import cPickle as pickle\n","else:\n","    import pickle\n","\n","import torch.utils.data as data\n","from torchvision.datasets.utils import download_url, check_integrity\n","\n","import csv\n","%matplotlib inline\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import os.path\n","import sys\n","import torch\n","import torch.utils.data\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","np.random.seed(111)\n","torch.cuda.manual_seed_all(111)\n","torch.manual_seed(111)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:00:19.997470Z","iopub.status.busy":"2023-10-08T06:00:19.996937Z","iopub.status.idle":"2023-10-08T06:00:20.018715Z","shell.execute_reply":"2023-10-08T06:00:20.017845Z","shell.execute_reply.started":"2023-10-08T06:00:19.997444Z"},"trusted":true},"outputs":[],"source":["\"\"\"\"\"\"\n","\n","class CIFAR10_SFU_CV(data.Dataset):\n","    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n","\n","    Args:\n","        root (string): Root directory of dataset where directory\n","            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n","        train (bool, optional): If True, creates dataset from training set, otherwise\n","            creates from test set.\n","        transform (callable, optional): A function/transform that  takes in an PIL image\n","            and returns a transformed version. E.g, ``transforms.RandomCrop``\n","        target_transform (callable, optional): A function/transform that takes in the\n","            target and transforms it.\n","        download (bool, optional): If true, downloads the dataset from the internet and\n","            puts it in root directory. If dataset is already downloaded, it is not\n","            downloaded again.\n","\n","    \"\"\"\n","    base_folder = 'cifar100'\n","    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n","    filename = \"cifar100.tar.gz\"\n","    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n","    train_list = [\n","        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n","        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n","        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n","        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n","        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n","    ]\n","\n","    test_list = [\n","        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n","    ]\n","\n","    def __init__(self, root, fold=\"train\",\n","                 transform=None, target_transform=None,\n","                 download=False):\n","        \n","        fold = fold.lower()\n","\n","        self.train = False\n","        self.test = False\n","        self.val = False\n","\n","        if fold == \"train\":\n","            self.train = True\n","        elif fold == \"test\":\n","            self.test = True\n","        elif fold == \"val\":\n","            self.val = True\n","        else:\n","            raise RuntimeError(\"Not train-val-test\")\n","\n","\n","        self.root = os.path.expanduser(root)\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","        fpath = os.path.join(root, self.filename)\n","        if not self._check_integrity():\n","            raise RuntimeError('Dataset not found or corrupted.' +\n","                               ' Download it and extract the file again.')\n","\n","        # now load the picked numpy arrays\n","        if self.train or self.val:\n","            self.train_data = []\n","            self.train_labels = []\n","            for fentry in self.train_list:\n","                f = fentry[0]\n","                file = os.path.join(self.root, self.base_folder, f)\n","                fo = open(file, 'rb')\n","                if sys.version_info[0] == 2:\n","                    entry = pickle.load(fo)\n","                else:\n","                    entry = pickle.load(fo, encoding='latin1')\n","                self.train_data.append(entry['data'])\n","                if 'labels' in entry:\n","                    self.train_labels += entry['labels']\n","                else:\n","                    self.train_labels += entry['fine_labels']\n","                fo.close()\n","\n","            self.train_data = np.concatenate(self.train_data)\n","            self.train_data = self.train_data.reshape((50000, 3, 32, 32))\n","            self.train_data = self.train_data.transpose((0, 2, 3, 1))  # convert to HWC\n","            \n","            p = np.arange(0,50000,10)\n","            mask_train = np.ones((50000,), dtype=bool)\n","            mask_train[p] = False\n","            mask_val = np.zeros((50000,), dtype=bool)\n","            mask_val[p] = True\n","\n","            copy_all_data = np.array(self.train_data)\n","            self.val_data = np.array(copy_all_data[mask_val])\n","            self.train_data = np.array(copy_all_data[mask_train])\n","            \n","            copy_all_labels = np.array(self.train_labels)\n","            self.val_labels = np.array(copy_all_labels[mask_val])\n","            self.train_labels = np.array(copy_all_labels[mask_train])\n","\n","        elif self.test:\n","            f = self.test_list[0][0]\n","            file = os.path.join(self.root, self.base_folder, f)\n","            fo = open(file, 'rb')\n","            if sys.version_info[0] == 2:\n","                entry = pickle.load(fo)\n","            else:\n","                entry = pickle.load(fo, encoding='latin1')\n","            self.test_data = entry['data']\n","\n","            if 'labels' in entry:\n","                self.test_labels = entry['labels']\n","            else:\n","                self.test_labels = entry['fine_labels']\n","            fo.close()\n","            self.test_data = self.test_data.reshape((10000, 3, 32, 32))\n","            self.test_data = self.test_data.transpose((0, 2, 3, 1))  # convert to HWC\n","\n","    def __getitem__(self, index):\n","        \"\"\"\n","        Args:\n","            index (int): Index\n","\n","        Returns:\n","            tuple: (image, target) where target is index of the target class.\n","        \"\"\"\n","        if self.train:\n","            img, target = self.train_data[index], self.train_labels[index]\n","        elif self.test:\n","            img, target = self.test_data[index], self.test_labels[index]\n","        elif self.val:\n","            img, target = self.val_data[index], self.val_labels[index]\n","\n","        # doing this so that it is consistent with all other datasets\n","        # to return a PIL Image\n","        img = Image.fromarray(img)\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","\n","        if self.target_transform is not None:\n","            target = self.target_transform(target)\n","\n","        return img, target\n","\n","    def __len__(self):\n","        if self.train:\n","            return len(self.train_data)\n","        elif self.test:\n","            return len(self.test_data)\n","        elif self.val:\n","            return len(self.val_data)\n","\n","    def _check_integrity(self):\n","        root = self.root\n","        for fentry in (self.train_list + self.test_list):\n","            filename, md5 = fentry[0], fentry[1]\n","            fpath = os.path.join(root, self.base_folder, filename)\n","            if not check_integrity(fpath, md5):\n","                return False\n","        return True\n","\n","    def __repr__(self):\n","        fmt_str = 'Dataset ' + self.__class__.__name__ + '\\n'\n","        fmt_str += '    Number of datapoints: {}\\n'.format(self.__len__())\n","        tmp = 'train' if self.train is True else 'test'\n","        fmt_str += '    Split: {}\\n'.format(tmp)\n","        fmt_str += '    Root Location: {}\\n'.format(self.root)\n","        tmp = '    Transforms (if any): '\n","        fmt_str += '{0}{1}\\n'.format(tmp, self.transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n","        tmp = '    Target Transforms (if any): '\n","        fmt_str += '{0}{1}'.format(tmp, self.target_transform.__repr__().replace('\\n', '\\n' + ' ' * len(tmp)))\n","        return fmt_str\n","\n","\n","class CIFAR100_SFU_CV(CIFAR10_SFU_CV):\n","    \"\"\"`CIFAR100 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n","\n","    This is a subclass of the `CIFAR10` Dataset.\n","    \"\"\"\n","    base_folder = 'cifar100'\n","    filename = \"cifar100.tar.gz\"\n","    tgz_md5 = 'e68a4c763591787a0b39fe2209371f32'\n","    train_list = [\n","        ['train_cs543', '49eee854445c1e2ebe796cd93c20bb0f'],\n","    ]\n","\n","    test_list = [\n","        ['test_cs543', 'd3fe9f6a9251bd443f428f896d27384f'],\n","    ]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:00:20.020739Z","iopub.status.busy":"2023-10-08T06:00:20.020122Z","iopub.status.idle":"2023-10-08T06:00:20.033542Z","shell.execute_reply":"2023-10-08T06:00:20.032532Z","shell.execute_reply.started":"2023-10-08T06:00:20.020708Z"},"trusted":true},"outputs":[],"source":["# <<TODO#5>> Based on the val set performance, decide how many\n","# epochs are apt for your model.\n","# ---------\n","EPOCHS = 50\n","# ---------\n","\n","IS_GPU = True\n","TEST_BS = 256\n","TOTAL_CLASSES = 100\n","TRAIN_BS = 32\n","PATH_TO_CIFAR100_SFU_CV = work_dir#\"/data/\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:00:20.035621Z","iopub.status.busy":"2023-10-08T06:00:20.034787Z","iopub.status.idle":"2023-10-08T06:00:21.030642Z","shell.execute_reply":"2023-10-08T06:00:21.029517Z","shell.execute_reply.started":"2023-10-08T06:00:20.035572Z"},"trusted":true},"outputs":[],"source":["ls /kaggle/working/cifar100/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:00:21.035385Z","iopub.status.busy":"2023-10-08T06:00:21.034718Z","iopub.status.idle":"2023-10-08T06:00:21.044152Z","shell.execute_reply":"2023-10-08T06:00:21.043061Z","shell.execute_reply.started":"2023-10-08T06:00:21.035344Z"},"trusted":true},"outputs":[],"source":["def calculate_val_accuracy(valloader, is_gpu):\n","    \"\"\" Util function to calculate val set accuracy,\n","    both overall and per class accuracy\n","    Args:\n","        valloader (torch.utils.data.DataLoader): val set \n","        is_gpu (bool): whether to run on GPU\n","    Returns:\n","        tuple: (overall accuracy, class level accuracy)\n","    \"\"\"    \n","    correct = 0.\n","    total = 0.\n","    predictions = []\n","\n","    class_correct = list(0. for i in range(TOTAL_CLASSES))\n","    class_total = list(0. for i in range(TOTAL_CLASSES))\n","\n","    for data in valloader:\n","        images, labels = data\n","        if is_gpu:\n","            images = images.cuda()\n","            labels = labels.cuda()\n","        outputs = net(Variable(images))\n","        _, predicted = torch.max(outputs.data, 1)\n","        predictions.extend(list(predicted.cpu().numpy()))\n","        total += labels.size(0)\n","        # The following line reported an error for some students. Put a new version.\n","        # correct += (predicted == labels).sum()\n","        correct += torch.sum(predicted == labels).detach().cpu().numpy()\n","\n","        # The following line reported an error for some students. Put a new version.\n","        # c = (predicted == labels).squeeze()\n","        c = torch.squeeze(predicted == labels).detach().cpu().numpy()\t\n","        # Added for a fix.\n","        # c = c.cpu()\n","        for i in range(len(labels)):\n","            label = labels[i]\n","            class_correct[label] += c[i]\n","            class_total[label] += 1\n","\n","    class_accuracy = 100 * np.divide(class_correct, class_total)\n","    return 100*correct/total, class_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:00:21.045975Z","iopub.status.busy":"2023-10-08T06:00:21.045631Z","iopub.status.idle":"2023-10-08T06:00:29.672082Z","shell.execute_reply":"2023-10-08T06:00:29.671088Z","shell.execute_reply.started":"2023-10-08T06:00:21.045940Z"},"trusted":true},"outputs":[],"source":["# The output of torchvision datasets are PILImage images of range [0, 1].\n","# Using transforms.ToTensor(), transform them to Tensors of normalized range\n","# [-1, 1].\n","\n","\n","# <<TODO#1>> Use transforms.Normalize() with the right parameters to \n","# make the data well conditioned (zero mean, std dev=1) for improved training.\n","# <<TODO#2>> Try using transforms.RandomCrop() and/or transforms.RandomHorizontalFlip()\n","# to augment training data.\n","# After your edits, make sure that test_transform should have the same data\n","# normalization parameters as train_transform\n","# You shouldn't have any data augmentation in test_transform (val or test data is never augmented).\n","# ---------------------\n","\n","train_transform = transforms.Compose(\n","    [transforms.ToTensor(), \n","     transforms.RandomHorizontalFlip(0.5),\n","#      transforms.RandomVerticalFlip(0.2),\n","     transforms.RandomCrop(28),\n","     transforms.Resize((32,32),antialias=True),\n","#      transforms.RandomRotation(10),\n","     transforms.RandomPerspective(distortion_scale=0.3,p=0.5), #minimal impact on overfitting\n","#      transforms.RandomAffine(25), #minimal impact on overfitting\n","     transforms.Normalize((0.5064, 0.4798, 0.4314),(0.2557, 0.2441, 0.2634)),\n","    ])\n","test_transform = transforms.Compose(\n","    [transforms.ToTensor(), \n","     transforms.Normalize((0.5064, 0.4798, 0.4314),(0.2557, 0.2441, 0.2634))\n","    ])\n","# ---------------------\n","\n","trainset = CIFAR100_SFU_CV(root=PATH_TO_CIFAR100_SFU_CV, fold=\"train\",\n","                                        download=True, transform=train_transform)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=TRAIN_BS,\n","                                          shuffle=True, num_workers=2)\n","print(\"Train set size: \"+str(len(trainset)))\n","\n","valset = CIFAR100_SFU_CV(root=PATH_TO_CIFAR100_SFU_CV, fold=\"val\",\n","                                       download=True, transform=test_transform)\n","valloader = torch.utils.data.DataLoader(valset, batch_size=TEST_BS,\n","                                         shuffle=False, num_workers=2)\n","print(\"Val set size: \"+str(len(valset)))\n","\n","testset = CIFAR100_SFU_CV(root=PATH_TO_CIFAR100_SFU_CV, fold=\"test\",\n","                                       download=True, transform=test_transform)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=TEST_BS,\n","                                         shuffle=False, num_workers=2)\n","print(\"Test set size: \"+str(len(testset)))\n","\n","# The 100 classes for CIFAR100\n","classes = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:00:29.674218Z","iopub.status.busy":"2023-10-08T06:00:29.673558Z","iopub.status.idle":"2023-10-08T06:00:29.679212Z","shell.execute_reply":"2023-10-08T06:00:29.678308Z","shell.execute_reply.started":"2023-10-08T06:00:29.674185Z"},"trusted":true},"outputs":[],"source":["# # https://www.geeksforgeeks.org/how-to-normalize-images-in-pytorch/\n","# # Adapted from: \n","# # https://www.binarystudy.com/2022/04/how-to-normalize-image-dataset-inpytorch.html\n","\n","# def batch_mean_and_sd(loader):\n","    \n","#     cnt = 0\n","#     fst_moment = torch.empty(3)\n","#     snd_moment = torch.empty(3)\n","\n","#     for images, _ in loader:\n","#         b, c, h, w = images.shape\n","#         nb_pixels = b * h * w\n","#         sum_ = torch.sum(images, dim=[0, 2, 3])\n","#         sum_of_square = torch.sum(images ** 2,\n","#                                   dim=[0, 2, 3])\n","#         fst_moment = (cnt * fst_moment + sum_) / (\n","#                       cnt + nb_pixels)\n","#         snd_moment = (cnt * snd_moment + sum_of_square) / (\n","#                             cnt + nb_pixels)\n","#         cnt += nb_pixels\n","\n","#     mean, std = fst_moment, torch.sqrt(\n","#       snd_moment - fst_moment ** 2)        \n","#     return mean,std"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:00:29.681359Z","iopub.status.busy":"2023-10-08T06:00:29.680395Z","iopub.status.idle":"2023-10-08T06:00:29.694900Z","shell.execute_reply":"2023-10-08T06:00:29.694085Z","shell.execute_reply.started":"2023-10-08T06:00:29.681330Z"},"trusted":true},"outputs":[],"source":["# mean, std = batch_mean_and_sd(trainloader)\n","# print(\"mean and std: \\n\", mean, std)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T07:04:36.565670Z","iopub.status.busy":"2023-10-08T07:04:36.565299Z","iopub.status.idle":"2023-10-08T07:04:37.033582Z","shell.execute_reply":"2023-10-08T07:04:37.032589Z","shell.execute_reply.started":"2023-10-08T07:04:36.565642Z"},"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class BaseNet(nn.Module):\n","    def __init__(self):\n","        super(BaseNet, self).__init__()\n","\n","        # <<TODO#3>> Add more conv layers with increasing\n","        # output channels\n","        # <<TODO#4>> Add normalization layers after conv\n","        # layers (nn.BatchNorm2d)\n","\n","        # Also experiment with kernel size in conv2d layers (say 3\n","        # inspired from VGGNet)\n","        # To keep it simple, keep the same kernel size\n","        # (right now set to 5) in all conv layers.\n","        # Do not have a maxpool layer after every conv layer in your\n","        # deeper network as it leads to too much loss of information.\n","\n","        self.conv1 = nn.Conv2d(3, 20, 3)\n","        self.norm1 = nn.BatchNorm2d(20)\n","\n","        self.conv2 = nn.Conv2d(20, 64, 3)\n","        self.norm2 = nn.BatchNorm2d(64)\n","\n","        self.conv3 = nn.Conv2d(64, 128, 3)\n","        self.norm3 = nn.BatchNorm2d(128)\n","\n","        self.conv4 = nn.Conv2d(128, 256, 3)\n","        self.norm4 = nn.BatchNorm2d(256)\n","\n","        self.conv5 = nn.Conv2d(256, 512, 3)\n","        self.norm5 = nn.BatchNorm2d(512)\n","\n","        self.conv6 = nn.Conv2d(512, 1024, 3)\n","        self.norm6 = nn.BatchNorm2d(1024)\n","\n","        self.pool = nn.MaxPool2d(2, 2)\n","\n","        # <<TODO#3>> Add more linear (fc) layers\n","        # <<TODO#4>> Add normalization layers after linear and\n","        # experiment inserting them before or after ReLU (nn.BatchNorm1d)\n","        # More on nn.sequential:\n","        # http://pytorch.org/docs/master/nn.html#torch.nn.Sequential\n","\n","        self.fc_net = nn.Sequential(\n","\n","#             nn.Linear(360 * 5 * 5, TOTAL_CLASSES//2),\n","            nn.Linear(1024 * 4 * 4, 2048),\n","#             nn.Linear(512*5*5,2048),\n","            nn.BatchNorm1d(2048),\n","            nn.ReLU(inplace=True),\n","            # nn.Dropout1d(p=0.1),\n","            nn.Linear(2048, 2048),\n","            nn.BatchNorm1d(2048),\n","            nn.ReLU(inplace=True),\n","            # nn.Dropout1d(p=0.2),\n","#             nn.Linear(2048, 1024),\n","#             nn.BatchNorm1d(1024),\n","#             nn.ReLU(inplace=True),\n","            # nn.Dropout1d(p=0.1), #0.1\n","            nn.Linear(2048, TOTAL_CLASSES),\n","        )\n","\n","    def forward(self, x):\n","\n","\n","        #input is coming in with 32x32\n","\n","        # first convolution 32 -> 30\n","        # second convolution 30 -> 28\n","        # third convolution 28 -> 26\n","        # fourth convolution 26 -> 24\n","        # pooling 24 -> 12\n","\n","        x = F.relu(self.norm1(self.conv1(x))) #input -> 32 -> 30\n","        x = F.relu(self.norm2(self.conv2(x))) #30 -> 28\n","        x = F.relu(self.norm3(self.conv3(x))) #28 -> 26\n","        x = self.pool(F.relu(self.norm4(self.conv4(x)))) #26 -> 24 -> 12  \n","        x = self.pool(F.relu(self.norm6(self.conv6(F.relu(self.norm5(self.conv5(x)))))))\n","        #12 -> 10 -> 8 -> 4 -> output\n","\n","        #the two convolutions with kernel sizes of 3 lead to\n","        # convolution 12 -> 10\n","        # pooling 10 -> 5\n","\n","        # channel num x output height x output width\n","        x = x.view(-1, 1024 * 4 * 4)\n","#         x = x.view(-1, 512 * 5 * 5)\n","        x = self.fc_net(x)\n","\n","        return x\n","\n","# Create an instance of the nn.module class defined above:\n","net = BaseNet()\n","\n","# For training on GPU, we need to transfer net and data onto the GPU\n","# http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu\n","if IS_GPU:\n","    net = net.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T07:04:37.058504Z","iopub.status.busy":"2023-10-08T07:04:37.058237Z","iopub.status.idle":"2023-10-08T07:04:37.066199Z","shell.execute_reply":"2023-10-08T07:04:37.065279Z","shell.execute_reply.started":"2023-10-08T07:04:37.058482Z"},"trusted":true},"outputs":[],"source":["########################################################################\n","# 3. Define a Loss function and optimizer\n","# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","# Here we use Cross-Entropy loss and SGD with momentum.\n","# The CrossEntropyLoss criterion already includes softmax within its\n","# implementation. That's why we don't use a softmax in our model\n","# definition.\n","\n","import torch.optim as optim\n","criterion = nn.CrossEntropyLoss()\n","\n","# Tune the learning rate.\n","# See whether the momentum is useful or not\n","optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9) #0.001 is best\n","# stepper = optim.lr_scheduler.StepLR(optimizer,10,0.5) #trying with the FC layer gone\n","stepper = optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max=EPOCHS)\n","\n","plt.ioff()\n","fig = plt.figure()\n","train_loss_over_epochs = []\n","val_accuracy_over_epochs = []\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T07:04:37.575990Z","iopub.status.busy":"2023-10-08T07:04:37.575630Z","iopub.status.idle":"2023-10-08T07:24:58.447635Z","shell.execute_reply":"2023-10-08T07:24:58.446326Z","shell.execute_reply.started":"2023-10-08T07:04:37.575962Z"},"trusted":true},"outputs":[],"source":["########################################################################\n","# 4. Train the network\n","# ^^^^^^^^^^^^^^^^^^^^\n","#\n","# We simply have to loop over our data iterator, and feed the inputs to the\n","# network and optimize. We evaluate the validation accuracy at each\n","# epoch and plot these values over the number of epochs\n","# Nothing to change here\n","# -----------------------------\n","for epoch in range(EPOCHS):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs\n","        inputs, labels = data\n","\n","        if IS_GPU:\n","            inputs = inputs.cuda()\n","            labels = labels.cuda()\n","\n","        # wrap them in Variable\n","        inputs, labels = Variable(inputs), Variable(labels)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","    \n","    stepper.step()\n","    \n","    # Normalizing the loss by the total number of train batches\n","    running_loss/=len(trainloader)\n","    print('[%d] loss: %.3f' %\n","          (epoch + 1, running_loss))\n","\n","    # Scale of 0.0 to 100.0\n","    # Calculate validation set accuracy of the existing model\n","    val_accuracy, val_classwise_accuracy = \\\n","        calculate_val_accuracy(valloader, IS_GPU)\n","    print('Accuracy of the network on the val images: %d %%' % (val_accuracy))\n","\n","    # # Optionally print classwise accuracies\n","    # for c_i in range(TOTAL_CLASSES):\n","    #     print('Accuracy of %5s : %2d %%' % (\n","    #         classes[c_i], 100 * val_classwise_accuracy[c_i]))\n","\n","    train_loss_over_epochs.append(running_loss)\n","    val_accuracy_over_epochs.append(val_accuracy)\n","# -----------------------------\n","\n","\n","# Plot train loss over epochs and val set accuracy over epochs\n","# Nothing to change here\n","# -------------\n","plt.subplot(2, 1, 1)\n","plt.ylabel('Train loss')\n","plt.plot(np.arange(EPOCHS), train_loss_over_epochs, 'k-')\n","plt.title('train loss and val accuracy')\n","plt.xticks(np.arange(EPOCHS, dtype=int))\n","plt.grid(True)\n","\n","plt.subplot(2, 1, 2)\n","# The line added for a bug fix.\n","val_accuracy_over_epochs = torch.tensor(val_accuracy_over_epochs, device = 'cpu')\n","\n","plt.plot(np.arange(EPOCHS), val_accuracy_over_epochs, 'b-')\n","plt.ylabel('Val accuracy')\n","plt.xlabel('Epochs')\n","plt.xticks(np.arange(EPOCHS, dtype=int))\n","plt.grid(True)\n","plt.savefig(\"plot.png\")\n","plt.close(fig)\n","print('Finished Training')\n","# -------------"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-08T06:56:55.760828Z","iopub.status.busy":"2023-10-08T06:56:55.759815Z","iopub.status.idle":"2023-10-08T06:56:56.233036Z","shell.execute_reply":"2023-10-08T06:56:56.231555Z","shell.execute_reply.started":"2023-10-08T06:56:55.760791Z"},"trusted":true},"outputs":[],"source":["########################################################################\n","# 5. Try the network on test data, and create .csv file\n","# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","########################################################################\n","\n","# Check out why .eval() is important!\n","# https://discuss.pytorch.org/t/model-train-and-model-eval-vs-model-and-model-eval/5744/2\n","net.eval()\n","\n","total = 0\n","predictions = []\n","for data in testloader:\n","    images, labels = data\n","\n","    # For training on GPU, we need to transfer net and data onto the GPU\n","    # http://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#training-on-gpu\n","    if IS_GPU:\n","        images = images.cuda()\n","        labels = labels.cuda()\n","    \n","    outputs = net(Variable(images))\n","    _, predicted = torch.max(outputs.data, 1)\n","    predictions.extend(list(predicted.cpu().numpy()))\n","    total += labels.size(0)\n","\n","with open('submission_netid.csv', 'w') as csvfile:\n","    wr = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n","    wr.writerow([\"Id\", \"Prediction1\"])\n","    for l_i, label in enumerate(predictions):\n","        wr.writerow([str(l_i), str(label)])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
